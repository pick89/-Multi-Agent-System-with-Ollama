# Multi-Agent System with Ollama & Telegram

# 1 Organization 
A production-ready multi-agent system that leverages Ollama's local LLMs with a hierarchical routing architecture and Telegram integration.

## Models 

### ===== TIER 1: ESSENTIAL =====
ollama pull gemma3:1b
ollama pull gemma3:4b
ollama pull qwen2.5-coder:3b
ollama pull qwen2.5-coder:7b
ollama pull phi4:14b

### ===== TIER 2: EXTENDED =====
ollama pull llama3.2-vision:11b
ollama pull minicpm-v:8b
ollama pull aya:8b
ollama pull nous-hermes2:10.7b
ollama pull mistral-nemo:12b
ollama pull qwen2.5:14b

### ===== TIER 3: MAXIMUM QUALITY =====
ollama pull gemma3:12b
ollama pull qwen2.5:32b
ollama pull deepseek-coder-v2:16b
ollama pull command-r:35b

## Agent Architecture with New Stack
```markdown 
INPUT â†’ gemma3:1b (Route) â†’ Specialist:
                            â”œâ”€â”€ Vision/Finance: gemma3:4b
                            â”œâ”€â”€ Code (fast): qwen2.5-coder:3b  
                            â”œâ”€â”€ Code (complex): qwen2.5-coder:7b
                            â”œâ”€â”€ Vision (heavy): qwen3-vl
                            â””â”€â”€ Agent/Tool: qwen3


ğŸ—ï¸ Architecture

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    INPUT LAYER                          â”‚
â”‚         (Email, Chat, Document, Voice)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ROUTER (gemma3:1b) - Instant classification            â”‚
â”‚  "What type of task? â†’ Route to specialist"             â”‚
â”‚  Priority: urgent/normal | Category: code/vision/text   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                 â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   VISION     â”‚  â”‚    CODE      â”‚  â”‚   ANALYSIS   â”‚
â”‚   PIPELINE   â”‚  â”‚   PIPELINE   â”‚  â”‚   PIPELINE   â”‚
â”‚              â”‚  â”‚              â”‚  â”‚              â”‚
â”‚ gemma3:4b    â”‚  â”‚ qwen2.5-coderâ”‚  â”‚   phi4:14b   â”‚
â”‚ (general)    â”‚  â”‚   :3b (fast) â”‚  â”‚ (deep think) â”‚
â”‚              â”‚  â”‚              â”‚  â”‚              â”‚
â”‚ llama3.2-vis â”‚  â”‚ qwen2.5-coderâ”‚  â”‚ qwen2.5:14b  â”‚
â”‚ :11b (complexâ”‚  â”‚   :7b (arch) â”‚  â”‚ (logic/math) â”‚
â”‚              â”‚  â”‚              â”‚  â”‚              â”‚
â”‚ minicpm-v:8b â”‚  â”‚ deepseek-codeâ”‚  â”‚ gemma3:12b   â”‚
â”‚ (OCR/docs)   â”‚  â”‚ r-v2:16b     â”‚  â”‚ (upgrade)    â”‚
â”‚              â”‚  â”‚ (complex)    â”‚  â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                 â”‚                 â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SYNTHESIZER (gemma3:4b or aya:8b)                      â”‚
â”‚  "Format output, generate response, update memory"      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
## 1.2 Data Flow Pipeline

1. User Input â†’ Telegram Message
2. Intent Classification â†’ gemma3:1b (50-100ms)
3. Task Routing â†’ Specialized Model
4. Processing â†’ Domain-Specific Execution
5. Synthesis â†’ Response Formatting
6. Output â†’ Telegram Reply

INPUT â†’ gemma3:1b (Router) â†’ Specialist Models â†’ Synthesizer â†’ Telegram


- **Router**: gemma3:1b (50-100ms intent classification)
- **Code**: qwen2.5-coder (3b/7b/16b) for fast/complex code generation
- **Vision**: gemma3:4b, llama3.2-vision:11b, minicpm-v:8b
- **Analysis**: phi4:14b, qwen2.5:14b for deep reasoning
- **Synthesis**: aya:8b for multilingual response formatting

## âœ¨ Features

- ğŸ¤– **Multi-Model Orchestration**: Automatic routing to specialized models
- ğŸ’¬ **Telegram Integration**: Full-featured bot with inline keyboards
- ğŸ“§ **Email Automation**: Fetch, prioritize, and reply to emails
- ğŸ’» **Code Generation**: Multi-language with execution testing
- ğŸ–¼ï¸ **Vision Processing**: Image analysis and OCR
- ğŸ” **Web Search**: Search and summarize information
- â° **Reminders**: Scheduled notifications
- ğŸ§  **Memory Management**: Redis-based conversation memory
- ğŸš€ **Production Ready**: Docker, Poetry, comprehensive logging

## ğŸ“‹ Prerequisites

- Python 3.11+
- [Poetry](https://python-poetry.org/)
- [Ollama](https://ollama.ai/)
- 16GB+ RAM (32GB+ recommended for maximum tier)
- NVIDIA GPU (optional, but recommended)

## ğŸš€ Quick Start

### 1. Clone and Install

```bash
git clone https://github.com/yourusername/multi-agent-system.git
cd multi-agent-system

# Install dependencies
poetry install

# Initialize project structure
poetry run agent-system init
```
### 2. Configure Environment
Edit .env file with your credentials:

```bash
# Required
TELEGRAM_BOT_TOKEN=your_bot_token_here

# Optional but recommended
EMAIL_ADDRESS=your.email@gmail.com
EMAIL_PASSWORD=your_app_password
```

### 3. Deploy Models
```bash
# Deploy essential models (minimum)
poetry run agent-system deploy-models essential

# Or deploy all models
poetry run agent-system deploy-models maximum
```

### 4. Run the Bot
```bash
# Polling mode (simpler)
poetry run agent-system run --polling

# Or webhook mode
poetry run agent-system run
```

ğŸ³ Docker Deployment
```bash
# Build and run with Docker Compose
docker-compose up -d

# Check logs
docker-compose logs -f
```
### ğŸ“ Project Structure
```bash
multi-agent-system/
â”œâ”€â”€ src/agent_system/     # Main package
â”‚   â”œâ”€â”€ core/            # Core orchestration
â”‚   â”œâ”€â”€ agents/          # Specialist agents
â”‚   â”œâ”€â”€ telegram/        # Telegram bot
â”‚   â”œâ”€â”€ memory/          # Memory management
â”‚   â””â”€â”€ automation/      # Automation modules
â”œâ”€â”€ tests/               # Test suite
â”œâ”€â”€ scripts/            # Utility scripts
â””â”€â”€ data/              # Data directory
```
### ğŸ¯ Usage Examples
#### Code Generation
```text
User: "Write a Python function to download files from URL"
Bot: Generates complete, tested Python code with error handling
```
### Email Management
```text
User: "Check my emails"
Bot: Fetches emails, prioritizes, suggests replies
```
### Vision Processing
```text
User: [Uploads image] "Extract text from this receipt"
Bot: OCR processing with minicpm-v:8b
```
### Deep Analysis
```text
User: "Analyze this dataset and find patterns"
Bot: Statistical analysis with phi4:14b
```
## âš™ï¸ Configuration
### Model Tiers
| Tier      | Models     | VRAM  | Use Case                     |
|-----------|------------|-------|------------------------------|
| Essential | 5 models   | 16GB  | Core functionality           |
| Extended  | +6 models  | 24GB  | Vision + Multilingual        |
| Maximum   | +4 models  | 32GB  | High-quality output          |

### Performance Optimization
- Router uses gemma3:1b (<100ms latency)
- Models load on-demand to save memory
- Response caching with Redis
- Async processing for concurrent users

## ğŸ”§ Development
```bash
# Run tests
poetry run pytest

# Format code
poetry run black .
poetry run isort .

# Type checking
poetry run mypy src

# Run linter
poetry run ruff check .
```
## ğŸ“Š Monitoring
- Prometheus metrics at `/metrics`
- Structured logging with Loguru
- Performance tracing
- Model usage statistics

## ğŸ¤ Contributing
Contributions are welcome! Please read our contributing guidelines.

## ğŸ“„ License
MIT License - see LICENSE file

## ğŸ™ Acknowledgments
- Ollama for local LLM deployment
- Python Telegram Bot library
- All the open-source models used

## âš ï¸ Disclaimer
This system runs LLMs locally. Ensure you have sufficient hardware resources. 
Email features require valid IMAP/SMTP credentials.


## ğŸš€ Installation & Setup Commands

```bash
# Complete setup from scratch
git clone <repository>
cd multi-agent-system

# Install Poetry if not installed
curl -sSL https://install.python-poetry.org | python3 -

# Install dependencies
poetry install

# Activate virtual environment
poetry shell

# Initialize project
poetry run agent-system init

# Edit .env file
nano .env  # or vim, code, etc.

# Deploy models
poetry run agent-system deploy-models essential

# Run the bot
poetry run agent-system run --polling
```


## ğŸ“Final Project Structure with All Files

```text
multi-agent-system/
â”‚
â”œâ”€â”€ ğŸ“„ pyproject.toml                 # Poetry configuration
â”œâ”€â”€ ğŸ“„ poetry.lock                   # Locked dependencies
â”œâ”€â”€ ğŸ“„ README.md                     # Project documentation
â”œâ”€â”€ ğŸ“„ .env.example                  # Template for environment variables
â”œâ”€â”€ ğŸ“„ .env                          # Your actual environment variables (create this!)
â”œâ”€â”€ ğŸ“„ .gitignore                    # Git ignore rules
â”œâ”€â”€ ğŸ“„ docker-compose.yml            # Docker Compose configuration
â”œâ”€â”€ ğŸ“„ Dockerfile                    # Docker build instructions
â”‚
â”œâ”€â”€ ğŸ“ scripts/                      # UTILITY SCRIPTS - Deployment & Tools
â”‚   â”œâ”€â”€ ğŸ“„ deploy_models.sh          # MAIN: Model deployment script (bash)
â”‚   â”œâ”€â”€ ğŸ“„ deploy_models.py         # Python version of model deployment
â”‚   â”œâ”€â”€ ğŸ“„ init_ollama.py           # Initialize Ollama connection
â”‚   â”œâ”€â”€ ğŸ“„ test_ollama.py           # Test Ollama connectivity
â”‚   â”œâ”€â”€ ğŸ“„ check_models.py          # Check which models are installed
â”‚   â”œâ”€â”€ ğŸ“„ benchmark_models.py      # Performance testing
â”‚   â””â”€â”€ ğŸ“„ setup.sh                 # One-command setup script
â”‚
â”œâ”€â”€ ğŸ“ src/                          # SOURCE CODE - Main application
â”‚   â””â”€â”€ ğŸ“ agent_system/            # Main package
â”‚       â”œâ”€â”€ ğŸ“„ __init__.py
â”‚       â”œâ”€â”€ ğŸ“„ main.py              # ENTRY POINT: CLI application
â”‚       â”œâ”€â”€ ğŸ“„ config.py            # Configuration management
â”‚       â”‚
â”‚       â”œâ”€â”€ ğŸ“ core/                # CORE ORCHESTRATION
â”‚       â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚       â”‚   â”œâ”€â”€ ğŸ“„ orchestrator.py  # MAIN: Coordinates all agents
â”‚       â”‚   â”œâ”€â”€ ğŸ“„ router_agent.py  # Router using gemma3:1b
â”‚       â”‚   â””â”€â”€ ğŸ“„ specialist_base.py # Base class for all agents
â”‚       â”‚
â”‚       â”œâ”€â”€ ğŸ“ agents/              # SPECIALIST AGENTS
â”‚       â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚       â”‚   â”œâ”€â”€ ğŸ“„ code_specialist.py  # Code generation with qwen-coder
â”‚       â”‚   â”œâ”€â”€ ğŸ“„ email_agent.py      # Email automation with phi4
â”‚       â”‚   â”œâ”€â”€ ğŸ“„ vision_agent.py     # Vision with llama3.2-vision
â”‚       â”‚   â”œâ”€â”€ ğŸ“„ analysis_agent.py   # Deep analysis with phi4
â”‚       â”‚   â”œâ”€â”€ ğŸ“„ search_agent.py     # Web search with qwen2.5
â”‚       â”‚   â””â”€â”€ ğŸ“„ synthesis_agent.py  # Response formatting with aya
â”‚       â”‚
â”‚       â”œâ”€â”€ ğŸ“ telegram/            # TELEGRAM INTEGRATION
â”‚       â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚       â”‚   â”œâ”€â”€ ğŸ“„ bot.py           # MAIN: Telegram bot setup
â”‚       â”‚   â”œâ”€â”€ ğŸ“„ handlers.py      # Command and message handlers
â”‚       â”‚   â”œâ”€â”€ ğŸ“„ keyboards.py     # Inline keyboard layouts
â”‚       â”‚   â””â”€â”€ ğŸ“„ callbacks.py     # Callback query handlers
â”‚       â”‚
â”‚       â”œâ”€â”€ ğŸ“ memory/              # MEMORY MANAGEMENT
â”‚       â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚       â”‚   â”œâ”€â”€ ğŸ“„ manager.py       # MAIN: Memory orchestration
â”‚       â”‚   â”œâ”€â”€ ğŸ“„ redis_client.py  # Redis connection
â”‚       â”‚   â”œâ”€â”€ ğŸ“„ vector_store.py  # Vector embeddings storage
â”‚       â”‚   â””â”€â”€ ğŸ“„ session.py       # User session management
â”‚       â”‚
â”‚       â”œâ”€â”€ ğŸ“ automation/          # AUTOMATION MODULES
â”‚       â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚       â”‚   â”œâ”€â”€ ğŸ“„ email_client.py  # Email fetching/sending
â”‚       â”‚   â”œâ”€â”€ ğŸ“„ code_executor.py # Code execution sandbox
â”‚       â”‚   â”œâ”€â”€ ğŸ“„ scheduler.py     # Task scheduler for reminders
â”‚       â”‚   â””â”€â”€ ğŸ“„ notification.py  # Notification system
â”‚       â”‚
â”‚       â”œâ”€â”€ ğŸ“ utils/               # UTILITIES
â”‚       â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚       â”‚   â”œâ”€â”€ ğŸ“„ logger.py        # Logging configuration
â”‚       â”‚   â”œâ”€â”€ ğŸ“„ validators.py    # Input validation
â”‚       â”‚   â”œâ”€â”€ ğŸ“„ helpers.py       # Helper functions
â”‚       â”‚   â””â”€â”€ ğŸ“„ metrics.py       # Performance metrics
â”‚       â”‚
â”‚       â””â”€â”€ ğŸ“ models/              # MODEL REGISTRY
â”‚           â”œâ”€â”€ ğŸ“„ __init__.py
â”‚           â”œâ”€â”€ ğŸ“„ schemas.py       # Pydantic schemas
â”‚           â””â”€â”€ ğŸ“„ model_registry.py # Model capabilities registry
â”‚
â”œâ”€â”€ ğŸ“ tests/                       # TESTS
â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”œâ”€â”€ ğŸ“„ conftest.py             # Pytest configuration
â”‚   â”œâ”€â”€ ğŸ“ unit/                   # Unit tests
â”‚   â”‚   â”œâ”€â”€ test_router.py
â”‚   â”‚   â”œâ”€â”€ test_code_agent.py
â”‚   â”‚   â””â”€â”€ test_email_agent.py
â”‚   â”œâ”€â”€ ğŸ“ integration/            # Integration tests
â”‚   â”‚   â”œâ”€â”€ test_orchestrator.py
â”‚   â”‚   â””â”€â”€ test_ollama.py
â”‚   â””â”€â”€ ğŸ“ fixtures/               # Test fixtures
â”‚       â””â”€â”€ sample_data.py
â”‚
â”œâ”€â”€ ğŸ“ data/                        # DATA DIRECTORY
â”‚   â”œâ”€â”€ ğŸ“ memory/                 # Persistent memory storage
â”‚   â”œâ”€â”€ ğŸ“ logs/                   # Application logs
â”‚   â”œâ”€â”€ ğŸ“ temp/                   # Temporary files
â”‚   â””â”€â”€ ğŸ“ models/                 # Local model cache
â”‚
â””â”€â”€ ğŸ“ docs/                       # DOCUMENTATION
    â”œâ”€â”€ ğŸ“„ architecture.md         # System architecture
    â”œâ”€â”€ ğŸ“„ api.md                  # API documentation
    â”œâ”€â”€ ğŸ“„ deployment.md           # Deployment guide
    â””â”€â”€ ğŸ“„ models.md              # Model specifications
```
