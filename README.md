# Multi-Agent System with Ollama & Telegram

# 1 Organization 
A production-ready multi-agent system that leverages Ollama's local LLMs with a hierarchical routing architecture and Telegram integration.

## Models 

### ===== TIER 1: ESSENTIAL =====
ollama pull gemma3:1b
ollama pull gemma3:4b
ollama pull qwen2.5-coder:3b
ollama pull qwen2.5-coder:7b
ollama pull phi4:14b

### ===== TIER 2: EXTENDED =====
ollama pull llama3.2-vision:11b
ollama pull minicpm-v:8b
ollama pull aya:8b
ollama pull nous-hermes2:10.7b
ollama pull mistral-nemo:12b
ollama pull qwen2.5:14b

### ===== TIER 3: MAXIMUM QUALITY =====
ollama pull gemma3:12b
ollama pull qwen2.5:32b
ollama pull deepseek-coder-v2:16b
ollama pull command-r:35b

## Agent Architecture with New Stack

INPUT â†’ gemma3:1b (Route) â†’ Specialist:
                            â”œâ”€â”€ Vision/Finance: gemma3:4b
                            â”œâ”€â”€ Code (fast): qwen2.5-coder:3b  
                            â”œâ”€â”€ Code (complex): qwen2.5-coder:7b
                            â”œâ”€â”€ Vision (heavy): qwen3-vl
                            â””â”€â”€ Agent/Tool: qwen3


## ğŸ—ï¸ Architecture

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    INPUT LAYER                          â”‚
â”‚         (Email, Chat, Document, Voice)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ROUTER (gemma3:1b) - Instant classification            â”‚
â”‚  "What type of task? â†’ Route to specialist"             â”‚
â”‚  Priority: urgent/normal | Category: code/vision/text   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                 â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   VISION     â”‚  â”‚    CODE      â”‚  â”‚   ANALYSIS   â”‚
â”‚   PIPELINE   â”‚  â”‚   PIPELINE   â”‚  â”‚   PIPELINE   â”‚
â”‚              â”‚  â”‚              â”‚  â”‚              â”‚
â”‚ gemma3:4b    â”‚  â”‚ qwen2.5-coderâ”‚  â”‚   phi4:14b   â”‚
â”‚ (general)    â”‚  â”‚   :3b (fast) â”‚  â”‚ (deep think) â”‚
â”‚              â”‚  â”‚              â”‚  â”‚              â”‚
â”‚ llama3.2-vis â”‚  â”‚ qwen2.5-coderâ”‚  â”‚ qwen2.5:14b  â”‚
â”‚ :11b (complexâ”‚  â”‚   :7b (arch) â”‚  â”‚ (logic/math) â”‚
â”‚              â”‚  â”‚              â”‚  â”‚              â”‚
â”‚ minicpm-v:8b â”‚  â”‚ deepseek-codeâ”‚  â”‚ gemma3:12b   â”‚
â”‚ (OCR/docs)   â”‚  â”‚ r-v2:16b     â”‚  â”‚ (upgrade)    â”‚
â”‚              â”‚  â”‚ (complex)    â”‚  â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                 â”‚                 â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SYNTHESIZER (gemma3:4b or aya:8b)                      â”‚
â”‚  "Format output, generate response, update memory"      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

## 1.2 Data Flow Pipeline

1. User Input â†’ Telegram Message
2. Intent Classification â†’ gemma3:1b (50-100ms)
3. Task Routing â†’ Specialized Model
4. Processing â†’ Domain-Specific Execution
5. Synthesis â†’ Response Formatting
6. Output â†’ Telegram Reply

INPUT â†’ gemma3:1b (Router) â†’ Specialist Models â†’ Synthesizer â†’ Telegram


- **Router**: gemma3:1b (50-100ms intent classification)
- **Code**: qwen2.5-coder (3b/7b/16b) for fast/complex code generation
- **Vision**: gemma3:4b, llama3.2-vision:11b, minicpm-v:8b
- **Analysis**: phi4:14b, qwen2.5:14b for deep reasoning
- **Synthesis**: aya:8b for multilingual response formatting

## âœ¨ Features

- ğŸ¤– **Multi-Model Orchestration**: Automatic routing to specialized models
- ğŸ’¬ **Telegram Integration**: Full-featured bot with inline keyboards
- ğŸ“§ **Email Automation**: Fetch, prioritize, and reply to emails
- ğŸ’» **Code Generation**: Multi-language with execution testing
- ğŸ–¼ï¸ **Vision Processing**: Image analysis and OCR
- ğŸ” **Web Search**: Search and summarize information
- â° **Reminders**: Scheduled notifications
- ğŸ§  **Memory Management**: Redis-based conversation memory
- ğŸš€ **Production Ready**: Docker, Poetry, comprehensive logging

## ğŸ“‹ Prerequisites

- Python 3.11+
- [Poetry](https://python-poetry.org/)
- [Ollama](https://ollama.ai/)
- 16GB+ RAM (32GB+ recommended for maximum tier)
- NVIDIA GPU (optional, but recommended)

## ğŸš€ Quick Start

### 1. Clone and Install

```bash
git clone https://github.com/yourusername/multi-agent-system.git
cd multi-agent-system

# Install dependencies
poetry install

# Initialize project structure
poetry run agent-system init
```
### 2. Configure Environment
Edit .env file with your credentials:

```bash
# Required
TELEGRAM_BOT_TOKEN=your_bot_token_here

# Optional but recommended
EMAIL_ADDRESS=your.email@gmail.com
EMAIL_PASSWORD=your_app_password
```

### 3. Deploy Models
```bash
# Deploy essential models (minimum)
poetry run agent-system deploy-models essential

# Or deploy all models
poetry run agent-system deploy-models maximum
```

### 4. Run the Bot
```bash
# Polling mode (simpler)
poetry run agent-system run --polling

# Or webhook mode
poetry run agent-system run
```

ğŸ³ Docker Deployment
```bash
# Build and run with Docker Compose
docker-compose up -d

# Check logs
docker-compose logs -f
```
### ğŸ“ Project Structure
```bash
multi-agent-system/
â”œâ”€â”€ src/agent_system/     # Main package
â”‚   â”œâ”€â”€ core/            # Core orchestration
â”‚   â”œâ”€â”€ agents/          # Specialist agents
â”‚   â”œâ”€â”€ telegram/        # Telegram bot
â”‚   â”œâ”€â”€ memory/          # Memory management
â”‚   â””â”€â”€ automation/      # Automation modules
â”œâ”€â”€ tests/               # Test suite
â”œâ”€â”€ scripts/            # Utility scripts
â””â”€â”€ data/              # Data directory
```
### ğŸ¯ Usage Examples
#### Code Generation
```text
User: "Write a Python function to download files from URL"
Bot: Generates complete, tested Python code with error handling
```
### Email Management
```text
User: "Check my emails"
Bot: Fetches emails, prioritizes, suggests replies
```
### Vision Processing
```text
User: [Uploads image] "Extract text from this receipt"
Bot: OCR processing with minicpm-v:8b
```
### Deep Analysis
```text
User: "Analyze this dataset and find patterns"
Bot: Statistical analysis with phi4:14b
```
## âš™ï¸ Configuration
### Model Tiers
| Tier      | Models     | VRAM  | Use Case                     |
|-----------|------------|-------|------------------------------|
| Essential | 5 models   | 16GB  | Core functionality           |
| Extended  | +6 models  | 24GB  | Vision + Multilingual        |
| Maximum   | +4 models  | 32GB  | High-quality output          |

### Performance Optimization
- Router uses gemma3:1b (<100ms latency)
- Models load on-demand to save memory
- Response caching with Redis
- Async processing for concurrent users

## ğŸ”§ Development
```bash
# Run tests
poetry run pytest

# Format code
poetry run black .
poetry run isort .

# Type checking
poetry run mypy src

# Run linter
poetry run ruff check .
```
## ğŸ“Š Monitoring
- Prometheus metrics at `/metrics`
- Structured logging with Loguru
- Performance tracing
- Model usage statistics

## ğŸ¤ Contributing
Contributions are welcome! Please read our contributing guidelines.

## ğŸ“„ License
MIT License - see LICENSE file

## ğŸ™ Acknowledgments
- Ollama for local LLM deployment
- Python Telegram Bot library
- All the open-source models used

## âš ï¸ Disclaimer
This system runs LLMs locally. Ensure you have sufficient hardware resources. 
Email features require valid IMAP/SMTP credentials.

```text

## ğŸš€ Installation & Setup Commands

```bash
# Complete setup from scratch
git clone <repository>
cd multi-agent-system

# Install Poetry if not installed
curl -sSL https://install.python-poetry.org | python3 -

# Install dependencies
poetry install

# Activate virtual environment
poetry shell

# Initialize project
poetry run agent-system init

# Edit .env file
nano .env  # or vim, code, etc.

# Deploy models
poetry run agent-system deploy-models essential

# Run the bot
poetry run agent-system run --polling
```



